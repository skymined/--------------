{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 잔차이탈도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 통계 모델에서 관측값과 모델이 예측한 값 사이의 차이르르 측정하는 지표\n",
    "- 특히 로지스틱 회귀와 같은 일반화 선형 모델(GLM)에서 자주 사용됨\n",
    "- 값이 작은 경우 모델이 데이터를 잘 설명하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잔차이탈도 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484393\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import logit\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 준비\n",
    "data = pd.DataFrame({\n",
    "    'x1': [1, 2, 3, 4, 5],\n",
    "    'x2': [5, 4, 3, 2, 1],\n",
    "    'y': [0, 1, 0, 1, 1]\n",
    "})\n",
    "\n",
    "# 로지스틱 회귀 모델 적합\n",
    "model = logit('y ~ x1 +x2', data=data).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>     5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 18 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.2803</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:22:21</td>     <th>  Log-Likelihood:    </th> <td> -2.4220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -3.3651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.3894</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0328</td> <td> 7.35e+07</td> <td> 4.46e-10</td> <td> 1.000</td> <td>-1.44e+08</td> <td> 1.44e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.6435</td> <td> 1.23e+07</td> <td> 5.25e-08</td> <td> 1.000</td> <td> -2.4e+07</td> <td>  2.4e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -0.4469</td> <td> 1.23e+07</td> <td>-3.65e-08</td> <td> 1.000</td> <td> -2.4e+07</td> <td>  2.4e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &        5    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &        2    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Date:}            & Mon, 18 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &   0.2803    \\\\\n",
       "\\textbf{Time:}            &     10:22:21     & \\textbf{  Log-Likelihood:    } &   -2.4220   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -3.3651   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &   0.3894    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       0.0328  &     7.35e+07     &  4.46e-10  &         1.000        &    -1.44e+08    &     1.44e+08     \\\\\n",
       "\\textbf{x1}        &       0.6435  &     1.23e+07     &  5.25e-08  &         1.000        &     -2.4e+07    &      2.4e+07     \\\\\n",
       "\\textbf{x2}        &      -0.4469  &     1.23e+07     & -3.65e-08  &         1.000        &     -2.4e+07    &      2.4e+07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                    5\n",
       "Model:                          Logit   Df Residuals:                        2\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 18 Nov 2024   Pseudo R-squ.:                  0.2803\n",
       "Time:                        10:22:21   Log-Likelihood:                -2.4220\n",
       "converged:                       True   LL-Null:                       -3.3651\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.3894\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0328   7.35e+07   4.46e-10      1.000   -1.44e+08    1.44e+08\n",
       "x1             0.6435   1.23e+07   5.25e-08      1.000    -2.4e+07     2.4e+07\n",
       "x2            -0.4469   1.23e+07  -3.65e-08      1.000    -2.4e+07     2.4e+07\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogitResults' object has no attribute 'deviance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 잔차이탈도 확인\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m잔차이탈도 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeviance\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m자유도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mdf_resid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\wrapper.py:34\u001b[0m, in \u001b[0;36mResultsWrapper.__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(results, attr)\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     36\u001b[0m how \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_attrs\u001b[38;5;241m.\u001b[39mget(attr)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogitResults' object has no attribute 'deviance'"
     ]
    }
   ],
   "source": [
    "# 잔차이탈도 확인\n",
    "print(f'잔차이탈도 : {model.deviance}')\n",
    "print(f'자유도: {model.df_resid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객 정보를 나타낸 데이터이다. 주어진 데이터에서 500개 중 앞에서부터 300개는 train으로, 200개는 test 데이터로 나눈다. 모델을 학습(적합)할 때는 train 데이터를 사용하고, 예측할 때는 test 데이터를 사용한다. 모델은 로지스틱 회귀를 써서 고객이 특정 제품을 구매할지 여부를 예측하되, 페널티는 부과하지 않는다.\n",
    "\n",
    "종속변수: purchase (0: 구매 안 함, 1: 구매 함)\n",
    "\n",
    "Q. age, income, marital_status 변수를 독립변수로 purchase를 종속변수로 사용하여 로지스틱 회귀 모형을 만들고, 잔차이탈도를 구하시오. (반올림하여 소수 넷째자리까지 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import logit\n",
    "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/Customer_Data.csv\")\n",
    "\n",
    "# 데이터셋 분할\n",
    "train = df.iloc[:300]\n",
    "test = df.iloc[300:]\n",
    "\n",
    "model = logit('purchase ~ age + income + marital_status', data=train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(-2 * model.llf,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary 만 보고 계산하면 소수점이 모두 나오지 않기 때문에 차이가 있음\n",
    "-2 * -206.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2 glm 활용\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "# 2) 잔차이탈도 계산# 1) glm 모델 적합 (로지스틱 회귀를 위해 이항 분포 사용)\n",
    "formula = \"purchase ~ age + income + marital_status\"\n",
    "model = glm(formula, data=train, family=sm.families.Binomial()).fit()\n",
    "print(model.summary())\n",
    "print(round(model.deviance,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
